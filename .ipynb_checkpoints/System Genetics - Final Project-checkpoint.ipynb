{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systems genetics 2020 - Final Project  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note!\n",
    "Our project is devided into several python modules which are loaded and excecuted from this notebook. <br>\n",
    "Most of our code's project can be found under the /modules directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import public packges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import custom packges (our python modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('modules')\n",
    "\n",
    "from utils import print_dim, print_stats\n",
    "from preprocessing import data_annotations_merge\n",
    "from regression import eqtl_analysis, qtl_analysis\n",
    "from results_analysis import get_associations, cis_trans_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bold_s = '\\033[1m'\n",
    "bold_e = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "liver_exp = pd.read_csv('data/GSE17522_series_matrix_liver.txt', sep = \"\\t\")\n",
    "brain_exp = pd.read_csv('data/GSE36674_series_matrix_hypothalamus.txt', sep = \"\\t\")\n",
    "\n",
    "liver_annotations = pd.read_csv('data/annotations_liver_GPL6466-9752.txt', sep = \"\\t\")\n",
    "brain_annotations = pd.read_csv('data/annotation_brain.annot', sep = \"\\t\")\n",
    "\n",
    "genotypes = pd.read_excel('data/genotypes.xls', headers=None)\n",
    "phenotypes = pd.read_excel('data/phenotypes.xls')\n",
    "\n",
    "mgi = pd.read_csv('data/MGI_Coordinates.Build37.rpt.txt', sep = \"\\t\", error_bad_lines=False, warn_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gene expression data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Merge data file with annotation file to get your input matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_annotations = brain_annotations.rename(columns={'Gene symbol' : 'GENE_SYMBOL'})\n",
    "brain_matrix = data_annotations_merge(brain_exp, brain_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "liver_matrix = data_annotations_merge(liver_exp, liver_annotations)\n",
    "\n",
    "# Keep BXD columns and identifier columns only\n",
    "liver_bxd_cols = list(liver_matrix.filter(regex=(\"BXD*\")).columns)\n",
    "id_cols = ['ID', 'GENE_SYMBOL']\n",
    "liver_matrix = liver_matrix[id_cols + liver_bxd_cols]\n",
    "\n",
    "# Rename BXD columns\n",
    "liver_matrix = liver_matrix.rename(columns={col : col.split('_')[1] + '_' + col.split('_')[2] \\\n",
    "                                            for col in liver_matrix.columns.drop(id_cols)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Keep only BXD columns that exists in the four files: genotypes, phenotypes and each tissue seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "genotypes_bxd_cols = list(genotypes.filter(regex=(\"BXD*\")).columns)\n",
    "phenotypes_bxd_cols = list(phenotypes.filter(regex=(\"BXD*\")).columns)\n",
    "\n",
    "genotypes_baseline_cols = [\"Locus\", \"Chr_Build37\", \"Build37_position\"]\n",
    "phenotypes_baseline_cols = [\"Phenotype\", \"Authors\", \"Year\", \"Pubmed Id\"]\n",
    "\n",
    "# liver common columns\n",
    "liver_matrix = liver_matrix.rename(columns = {col : col.split('_')[0] for col in liver_matrix.drop(columns = id_cols)}) \n",
    "liver_bxd_cols = list(liver_matrix.filter(regex='BXD').columns)\n",
    "liver_common_bxd = list(set(genotypes_bxd_cols) & set(phenotypes_bxd_cols) &  set(liver_bxd_cols))\n",
    "liver_common_bxd.sort()\n",
    "liver_matrix = liver_matrix[['GENE_SYMBOL'] + liver_common_bxd]\n",
    "liver_genotypes = genotypes[genotypes_baseline_cols + liver_common_bxd]\n",
    "liver_phenotypes = phenotypes[phenotypes_baseline_cols + liver_common_bxd]\n",
    "\n",
    "# brain common columns\n",
    "brain_matrix = brain_matrix.rename(columns = {col : col.split('_')[0] for col in brain_matrix.drop(columns = id_cols)}) \n",
    "brain_bxd_cols = list(brain_matrix.filter(regex='BXD').columns)\n",
    "brain_common_bxd = list(set(genotypes_bxd_cols) & set(phenotypes_bxd_cols) &  set(brain_bxd_cols))\n",
    "brain_common_bxd.sort()\n",
    "brain_matrix = brain_matrix[['GENE_SYMBOL'] + brain_common_bxd]\n",
    "brain_genotypes = genotypes[genotypes_baseline_cols + brain_common_bxd]\n",
    "brain_phenotypes = phenotypes[phenotypes_baseline_cols + brain_common_bxd]\n",
    "\n",
    "# drop empty lines from phenotypes file\n",
    "brain_phenotypes = brain_phenotypes.iloc[brain_phenotypes[brain_common_bxd].dropna(how='all').index]\n",
    "liver_phenotypes = liver_phenotypes.iloc[liver_phenotypes[liver_common_bxd].dropna(how='all').index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Use only representative genomic loci - Drop duplicated rows (of neighboring loci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIVER Genotypes: Drop duplications:\n",
      "#SNPs before: 3796   -->   #SNPs after: 1403\n",
      "LIVER Genotypes: Drop duplications:\n",
      "#SNPs before: 3796   -->   #SNPs after: 1598\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Locus</th>\n",
       "      <th>Chr_Build37</th>\n",
       "      <th>Build37_position</th>\n",
       "      <th>BXD1</th>\n",
       "      <th>BXD100</th>\n",
       "      <th>BXD101</th>\n",
       "      <th>BXD102</th>\n",
       "      <th>BXD103</th>\n",
       "      <th>BXD11</th>\n",
       "      <th>BXD12</th>\n",
       "      <th>...</th>\n",
       "      <th>BXD80</th>\n",
       "      <th>BXD83</th>\n",
       "      <th>BXD84</th>\n",
       "      <th>BXD85</th>\n",
       "      <th>BXD87</th>\n",
       "      <th>BXD89</th>\n",
       "      <th>BXD90</th>\n",
       "      <th>BXD95</th>\n",
       "      <th>BXD97</th>\n",
       "      <th>BXD99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rs6269442</td>\n",
       "      <td>1</td>\n",
       "      <td>3482276</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>D</td>\n",
       "      <td>H</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rs6376963</td>\n",
       "      <td>1</td>\n",
       "      <td>5008090</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>D</td>\n",
       "      <td>H</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rs3677817</td>\n",
       "      <td>1</td>\n",
       "      <td>5176059</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>D</td>\n",
       "      <td>H</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rs8236463</td>\n",
       "      <td>1</td>\n",
       "      <td>5579194</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>D</td>\n",
       "      <td>H</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rs6298633</td>\n",
       "      <td>1</td>\n",
       "      <td>6820242</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>D</td>\n",
       "      <td>H</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Locus  Chr_Build37  Build37_position BXD1 BXD100 BXD101 BXD102 BXD103  \\\n",
       "0  rs6269442            1           3482276    B      B      U      U      U   \n",
       "2  rs6376963            1           5008090    B      B      U      U      U   \n",
       "3  rs3677817            1           5176059    B      B      U      U      U   \n",
       "4  rs8236463            1           5579194    B      B      U      U      U   \n",
       "6  rs6298633            1           6820242    B      B      U      U      U   \n",
       "\n",
       "  BXD11 BXD12  ... BXD80 BXD83 BXD84 BXD85 BXD87 BXD89 BXD90 BXD95 BXD97 BXD99  \n",
       "0     B     D  ...     D     H     B     D     B     B     B     D     B     B  \n",
       "2     B     D  ...     D     H     B     D     B     B     B     D     B     B  \n",
       "3     B     D  ...     D     H     B     D     B     B     B     D     B     B  \n",
       "4     D     D  ...     D     H     B     D     B     B     B     D     B     B  \n",
       "6     D     D  ...     D     H     B     D     B     B     B     D     B     B  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# liver genotypes filtering\n",
    "snps_org = len(liver_genotypes)\n",
    "\n",
    "bxd_data = liver_genotypes[liver_common_bxd]\n",
    "duplicates_indx = bxd_data[bxd_data.shift() != bxd_data].dropna(how='all').index\n",
    "liver_genotypes = liver_genotypes.loc[duplicates_indx]\n",
    "\n",
    "print(\"LIVER Genotypes: Drop duplications:\\n#SNPs before: %d   -->   #SNPs after: %d\" % (snps_org, len(liver_genotypes)))\n",
    "liver_genotypes.head(5)\n",
    "\n",
    "# Brain genotypes filtering\n",
    "snps_org = len(brain_genotypes)\n",
    "\n",
    "bxd_data = brain_genotypes[brain_common_bxd]\n",
    "duplicates_indx = bxd_data[bxd_data.shift() != bxd_data].dropna(how='all').index\n",
    "brain_genotypes = brain_genotypes.loc[duplicates_indx]\n",
    "\n",
    "print(\"LIVER Genotypes: Drop duplications:\\n#SNPs before: %d   -->   #SNPs after: %d\" % (snps_org, len(brain_genotypes)))\n",
    "brain_genotypes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Remove rows with no gene identifier, <br> • Remove rows with low maximal value.  <br> • Remove rows with low variance.  <br> • Average multiple rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of rows after removing all rows with maximal values less than 0.70: 7772 \n",
      "Num of rows after removing all rows with variance less than 0.20: 1308 \n",
      "Num of rows after removing duplicated rows: %d  1285\n"
     ]
    }
   ],
   "source": [
    "max_treshold = 0.7\n",
    "var_treshold = 0.2\n",
    "\n",
    "# Remove rows with no gene identifier\n",
    "liver_matrix = liver_matrix[~liver_matrix['GENE_SYMBOL'].isna()]\n",
    "liver_bxd_cols = list(liver_matrix.filter(regex=(\"BXD*\")).columns)\n",
    "\n",
    "for col in liver_bxd_cols:\n",
    "    liver_matrix[col] = liver_matrix[col].astype('float64')\n",
    "\n",
    "# Filter by maximal value\n",
    "liver_matrix['max'] = liver_matrix.drop(columns=['GENE_SYMBOL']).max(axis=1)\n",
    "liver_matrix = liver_matrix[liver_matrix['max'] >= max_treshold]\n",
    "liver_matrix = liver_matrix.drop(columns = 'max')\n",
    "print(\"Num of rows after removing all rows with maximal values less than %.2f: %d \" % (max_treshold, len(liver_matrix)))\n",
    "\n",
    "# Filter by variance\n",
    "liver_matrix['var'] = liver_matrix.drop(columns=['GENE_SYMBOL']).var(axis=1)\n",
    "liver_matrix = liver_matrix[liver_matrix['var'] >= var_treshold]\n",
    "liver_matrix = liver_matrix.drop(columns = 'var')\n",
    "print(\"Num of rows after removing all rows with variance less than %.2f: %d \" % (var_treshold, len(liver_matrix)))\n",
    "\n",
    "# Group multiple rows by mean\n",
    "liver_matrix = liver_matrix.groupby('GENE_SYMBOL').agg('mean').reset_index()\n",
    "print(\"Num of rows after removing duplicated rows: %d \", len(liver_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of rows after removing all rows with maximal values less than 9.00: 9893 \n",
      "Num of rows after removing all rows with variance less than 0.04: 1444 \n",
      "Num of rows after removing duplicated rows: %d  1247\n"
     ]
    }
   ],
   "source": [
    "max_treshold = 9\n",
    "var_treshold = 0.04\n",
    "\n",
    "# Remove rows with no gene identifier\n",
    "brain_matrix = brain_matrix[~brain_matrix['GENE_SYMBOL'].isna()]\n",
    "brain_bxd_cols = list(brain_matrix.filter(regex=(\"BXD*\")).columns)\n",
    "\n",
    "for col in brain_bxd_cols:\n",
    "    brain_matrix[col] = brain_matrix[col].astype('float64')\n",
    "\n",
    "# Filter by maximal value\n",
    "brain_matrix['max'] = brain_matrix.drop(columns=['GENE_SYMBOL']).max(axis=1)\n",
    "brain_matrix = brain_matrix[brain_matrix['max'] >= max_treshold]\n",
    "brain_matrix = brain_matrix.drop(columns = 'max')\n",
    "print(\"Num of rows after removing all rows with maximal values less than %.2f: %d \" % (max_treshold, len(brain_matrix)))\n",
    "\n",
    "# Filter by variance\n",
    "brain_matrix['var'] = brain_matrix.drop(columns=['GENE_SYMBOL']).var(axis=1)\n",
    "brain_matrix = brain_matrix[brain_matrix['var'] >= var_treshold]\n",
    "brain_matrix = brain_matrix.drop(columns = 'var')\n",
    "print(\"Num of rows after removing all rows with variance less than %.2f: %d \" % (var_treshold, len(brain_matrix)))\n",
    "\n",
    "# Group multiple rows by mean\n",
    "brain_matrix = brain_matrix.groupby('GENE_SYMBOL').agg('mean').reset_index()\n",
    "print(\"Num of rows after removing duplicated rows: %d \", len(brain_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### • Average across different individuals of the same strain (Females and males)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "liver_matrix = liver_matrix.rename(columns = {col : col.split('_')[0] for col in liver_matrix.drop(columns = ['GENE_SYMBOL'])}) \n",
    "liver_matrix = liver_matrix.set_index(['GENE_SYMBOL']) \n",
    "liver_matrix = liver_matrix.groupby(by=liver_matrix.columns, axis=1).mean()\n",
    "liver_matrix = liver_matrix.reset_index()\n",
    "\n",
    "brain_matrix = brain_matrix.rename(columns = {col : col.split('_')[0] for col in brain_matrix.drop(columns = ['GENE_SYMBOL'])}) \n",
    "brain_matrix = brain_matrix.set_index(['GENE_SYMBOL']) \n",
    "brain_matrix = brain_matrix.groupby(by=brain_matrix.columns, axis=1).mean()\n",
    "brain_matrix = brain_matrix.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. eQTL analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run  Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liver: \n",
      "* Expression matrix size: 1285\n",
      "* Genotype matrix size: 1403\n",
      "* Expected num of tests: 1,802,855\n",
      "\n",
      "Brain: \n",
      "* Expression matrix size: 1247\n",
      "* Genotype matrix size: 1598\n",
      "* Expected num of tests: 1,992,706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_dim(len(liver_matrix), len(liver_genotypes), title=\"Liver: \")\n",
    "print_dim(len(brain_matrix), len(brain_genotypes), title=\"Brain: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Brain eqtl\n",
    "if not os.path.exists(\"brain_reg_results.csv\"):\n",
    "    brain_eqtls = eqtl_analysis(brain_matrix, brain_genotypes, file_prefix=\"brain_\")\n",
    "else:\n",
    "    brain_eqtls = pd.read_csv(\"brain_reg_results.csv\")\n",
    "    brain_eqtls = brain_eqtls.drop(columns='Unnamed: 0')\n",
    "    \n",
    "# Liver eqtl\n",
    "if not os.path.exists(\"liver_reg_results.csv\"):\n",
    "    liver_eqtls = eqtl_analysis(liver_matrix, liver_genotypes, file_prefix=\"liver_\")\n",
    "else:\n",
    "    liver_eqtls = pd.read_csv(\"liver_reg_results.csv\")\n",
    "    liver_eqtls = liver_eqtls.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cis/Trans annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1247/1247 [05:05<00:00,  4.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1285/1285 [05:09<00:00,  4.15it/s]\n"
     ]
    }
   ],
   "source": [
    "brain_eqtls = cis_trans_annotation(brain_eqtls.copy(), mgi)\n",
    "liver_eqtls = cis_trans_annotation(liver_eqtls.copy(), mgi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple test correction and associations filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1. Brain\u001b[0m\n",
      "\u001b[1mNumber of tests: \u001b[0m 1992706\n",
      "\n",
      "\u001b[1mNumber of different significant eQTLs: \u001b[0m 472\n",
      "From which: \n",
      " 260 - cis-acting \n",
      " 231 - trans-acting \n",
      "\n",
      "\u001b[1mNumber of total significant eQTLs: \u001b[0m 868\n",
      "From which: \n",
      " 349 - cis-acting \n",
      " 337 - trans-acting \n",
      "\u001b[1m\n",
      "\n",
      "2. Liver\u001b[0m\n",
      "\u001b[1mNumber of tests: \u001b[0m 1802855\n",
      "\n",
      "\u001b[1mNumber of different significant eQTLs: \u001b[0m 481\n",
      "From which: \n",
      " 261 - cis-acting \n",
      " 278 - trans-acting \n",
      "\n",
      "\u001b[1mNumber of total significant eQTLs: \u001b[0m 840\n",
      "From which: \n",
      " 325 - cis-acting \n",
      " 468 - trans-acting \n"
     ]
    }
   ],
   "source": [
    "brain_associations, brain_num_tests = get_associations(brain_eqtls) # by bonfferoni corrections\n",
    "brain_associations.to_csv(\"brain_assoc_eqtl.csv\")\n",
    "\n",
    "liver_associations, liver_num_tests = get_associations(liver_eqtls) # by bonfferoni corrections\n",
    "liver_associations.to_csv(\"brain_assoc_eqtl.csv\")\n",
    "\n",
    "print_stats(brain_associations, brain_num_tests, \"1. Brain\")\n",
    "print_stats(liver_associations, liver_num_tests, \"\\n\\n2. Liver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. QTL analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Currently looks like no morphine phenotype is significant.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all phenotypes related to Morphine by naive text search\n",
    "morphine_phenotypes_b = brain_phenotypes[brain_phenotypes['Phenotype'].str.contains(\"Morphine\")]\n",
    "morphine_phenotypes_l = liver_phenotypes[liver_phenotypes['Phenotype'].str.contains(\"Morphine\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 115/115 [11:52<00:00,  6.20s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 115/115 [10:43<00:00,  5.60s/it]\n"
     ]
    }
   ],
   "source": [
    "logpval_brain = qtl_analysis(morphine_phenotypes_b, brain_genotypes, file_prefix=\"brain_morphine_\")\n",
    "logpval_liver = qtl_analysis(morphine_phenotypes_l, liver_genotypes, file_prefix=\"liver_morphine_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc_qtl_l, ntests_qtl_l = get_associations(logpval_brain) # by bonfferoni corrections\n",
    "assoc_qtl_b, ntests_qtl_b = get_associations(logpval_liver) # by bonfferoni corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Causality Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_L_dependent_dist_params(df, A, l):\n",
    "    \"\"\" Calculate the parameters of the distribution A|L=l.\n",
    "        L can get 0 or 1\n",
    "        The event 'A' can be a complex trait (C) or a gene expression (R)\n",
    "    \"\"\"\n",
    "    obs = df[df.L == l][A]\n",
    "    mu = obs.mean()\n",
    "    var = obs.var(ddof=0)\n",
    "    \n",
    "    df[A + '|L_mean'][df.L == l] = mu\n",
    "    df[A + '|L_var'][df.L == l] = var\n",
    "    return df\n",
    "\n",
    "def get_columns_params(col_a, col_b):\n",
    "    # column A parameters\n",
    "    mu_a = col_a.mean()\n",
    "    var_a = col_a.var(ddof=0)\n",
    "    # column B parameters\n",
    "    mu_b = col_b.mean()\n",
    "    var_b = col_b.var(ddof=0)\n",
    "    # Correlation coef. between A and B\n",
    "    corr = col_a.corr(col_b)\n",
    "    return mu_a, var_a, mu_b, var_b, corr\n",
    "\n",
    "\n",
    "def get_conditional_dist_params(mu_a, var_a, mu_b, var_b, corr, b_i):\n",
    "    \"\"\" Calculate the parameters of the conditional distribution A|B (in our case it could be C|R or R|C)  \n",
    "        The calculation is a bit different compared to the conditional probability given L\n",
    "    \"\"\"\n",
    "    std_a = np.sqrt(var_a)\n",
    "    std_b = np.sqrt(var_b)\n",
    "    mu = mu_a + corr*std_a/std_b * (b_i - mu_b)\n",
    "    var = var_a * (1-np.square(corr))\n",
    "    return mu, var  \n",
    "\n",
    "def norm_pdf(x, mean, var):\n",
    "    denom = np.sqrt(2 * math.pi * var)\n",
    "    num = math.exp(-np.square(x-mean)/(2*var))\n",
    "    return (num/denom)\n",
    "\n",
    "def init_models(input_table):\n",
    "    m1_df = pd.DataFrame(columns=['Individual', 'L', 'R', 'C', \n",
    "                                   'R|L_mean', 'R|L_var', \n",
    "                                   'C|R_mean', 'C|R_var',\n",
    "                                   'P(R|L)', 'P(C|R)',\n",
    "                                   'P(L) * P(C|R) * P(R|L)'])\n",
    "    m1_df[['Individual', 'L', 'R', 'C']] = input_table\n",
    "\n",
    "    m2_df = pd.DataFrame(columns=['Individual', 'L', 'R', 'C', \n",
    "                                   'C|L_mean', 'C|L_var', \n",
    "                                   'R|C_mean', 'R|C_var',\n",
    "                                   'P(C|L)', 'P(R|C)',\n",
    "                                   'P(L) * P(R|C) * P(C|L)'])\n",
    "    m2_df[['Individual', 'L', 'R', 'C']] = input_table\n",
    "\n",
    "    m3_df = pd.DataFrame(columns=['Individual', 'L', 'R', 'C', \n",
    "                                   'R|L_mean', 'R|L_var', \n",
    "                                   'C|L_mean', 'C|L_var',\n",
    "                                   'P(R|L)', 'P(C|L)',\n",
    "                                   'P(L) * P(R|L) * P(C|L)'])\n",
    "    m3_df[['Individual', 'L', 'R', 'C']] = input_table\n",
    "    \n",
    "    return m1_df, m2_df, m3_df\n",
    "\n",
    "def generate_models_df(input_table):\n",
    "    # Three models tables init\n",
    "    m1_df, m2_df, m3_df = init_models(input_table)\n",
    "    \n",
    "    # Get and set the parameters of R|L distribution in models M1 and M3\n",
    "    m1_df = get_L_dependent_dist_params(m1_df, 'R', l=0)\n",
    "    m1_df = get_L_dependent_dist_params(m1_df, 'R', l=1)\n",
    "    m3_df = get_L_dependent_dist_params(m3_df, 'R', l=0)\n",
    "    m3_df = get_L_dependent_dist_params(m3_df, 'R', l=1)\n",
    "\n",
    "    # Get and set the parameters of C|L distribution models M2 and M3\n",
    "    m2_df = get_L_dependent_dist_params(m2_df, 'C', l=0)\n",
    "    m2_df = get_L_dependent_dist_params(m2_df, 'C', l=1)\n",
    "    m3_df = get_L_dependent_dist_params(m3_df, 'C', l=0)\n",
    "    m3_df = get_L_dependent_dist_params(m3_df, 'C', l=1)\n",
    "\n",
    "    # Calculate C|R and R|C parameters\n",
    "    mu_r, var_r, mu_c, var_c, corr_r_c = get_columns_params(input_table['R'], input_table['C'])\n",
    "    n = len(m1_df)\n",
    "    for i in range(0, n): \n",
    "        # C|R\n",
    "        r_i = m1_df['R'].iloc[i]\n",
    "        mu, var = get_conditional_dist_params(mu_c, var_c, mu_r, var_r, corr_r_c, r_i)\n",
    "        m1_df.iloc[i, m1_df.columns.get_loc('C|R_mean')] = mu\n",
    "        m1_df.iloc[i, m1_df.columns.get_loc('C|R_var')] = var\n",
    "        # R|C\n",
    "        c_i = m2_df['C'].iloc[i]\n",
    "        mu, var = get_conditional_dist_params(mu_r, var_r, mu_c, var_c, corr_r_c, c_i) \n",
    "        m2_df.iloc[i, m2_df.columns.get_loc('R|C_mean')] = mu\n",
    "        m2_df.iloc[i, m2_df.columns.get_loc('R|C_var')] = var\n",
    "\n",
    "    # Calculate normal dist. values for all models\n",
    "    m1_df['P(R|L)'] = m1_df.apply(lambda x: norm_pdf(x['R'], x['R|L_mean'], x['R|L_var']), axis=1)\n",
    "    m1_df['P(C|R)'] = m1_df.apply(lambda x: norm_pdf(x['C'], x['C|R_mean'], x['C|R_var']), axis=1)\n",
    "\n",
    "    m2_df['P(C|L)'] = m2_df.apply(lambda x: norm_pdf(x['C'], x['C|L_mean'], x['C|L_var']), axis=1)\n",
    "    m2_df['P(R|C)'] = m2_df.apply(lambda x: norm_pdf(x['R'], x['R|C_mean'], x['R|C_var']), axis=1)\n",
    "\n",
    "    m3_df['P(R|L)'] = m3_df.apply(lambda x: norm_pdf(x['R'], x['R|L_mean'], x['R|L_var']), axis=1)\n",
    "    m3_df['P(C|L)'] = m3_df.apply(lambda x: norm_pdf(x['C'], x['C|L_mean'], x['C|L_var']), axis=1)\n",
    "\n",
    "    m1_df['P(L) * P(C|R) * P(R|L)'] = 0.5 * m1_df['P(C|R)'] * m1_df['P(R|L)']\n",
    "    m2_df['P(L) * P(R|C) * P(C|L)'] = 0.5 * m2_df['P(R|C)'] * m2_df['P(C|L)']\n",
    "    m3_df['P(L) * P(R|L) * P(C|L)'] = 0.5 * m3_df['P(C|L)'] * m3_df['P(R|L)']\n",
    "    \n",
    "    # Save as excel file\n",
    "    m1_df.to_excel(\"likelihood_formulas_M1.xlsx\")\n",
    "    m2_df.to_excel(\"likelihood_formulas_M2.xlsx\")\n",
    "    m3_df.to_excel(\"likelihood_formulas_M3.xlsx\")\n",
    "    \n",
    "    return m1_df, m2_df, m3_df\n",
    "\n",
    "def get_LR(m1_df, m2_df, m3_df):\n",
    "    L_m1 = m1_df['P(L) * P(C|R) * P(R|L)'].prod()\n",
    "    L_m2 = m2_df['P(L) * P(R|C) * P(C|L)'].prod()\n",
    "    L_m3 = m3_df['P(L) * P(R|L) * P(C|L)'].prod()\n",
    "    likelihood_arr = [L_m1, L_m2, L_m3]\n",
    "\n",
    "    # Get max likelihoos\n",
    "    max_model = np.argmax([L_m1, L_m2, L_m3])\n",
    "    others_models = [x for i,x in enumerate(range(0,3)) if i != max_model] \n",
    "\n",
    "    # Calculate the likelihood ratio\n",
    "    LR = likelihood_arr[max_model] / max(likelihood_arr[others_models[0]], likelihood_arr[others_models[1]]) \n",
    "    return LR\n",
    "\n",
    "\n",
    "def get_shuffled_df(df):\n",
    "    \"\"\" Returns the given dataframe with 2 columns randomly shuffeled (L, R).\n",
    "        No need to randomize the 3rd column \"\"\"\n",
    "    df['L'] = df['L'].sample(frac = 1).values\n",
    "    df['R'] = df['R'].sample(frac = 1).values\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a triplet L, R, C for the causality analysis\n",
    "locus_idx = 241      # genotype\n",
    "gene_exp_idx = 288 \n",
    "phenotype_idx = 1842\n",
    "\n",
    "locus = liver_genotypes.loc[[locus_idx]].replace({'B': 0, 'b': 0, 'D':1, 'H': np.nan, 'U': np.nan})[liver_common_bxd]\n",
    "gene_exp = liver_matrix.iloc[[gene_exp_idx]][liver_common_bxd]\n",
    "phenotype = liver_phenotypes.loc[[phenotype_idx]][liver_common_bxd]\n",
    "\n",
    "# Create input table \n",
    "input_table = pd.concat([locus, gene_exp, phenotype]) # concate data types\n",
    "input_table = input_table.T.reset_index()             # transpose\n",
    "input_table.columns = ['Individual', 'L', 'R', 'C']\n",
    "input_table = input_table.dropna()                    # ignore nulls\n",
    "input_table = input_table.sort_values(by='L')         # sort by lucus (genotype 0 or 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Individual</th>\n",
       "      <th>L</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>R|L_mean</th>\n",
       "      <th>R|L_var</th>\n",
       "      <th>C|R_mean</th>\n",
       "      <th>C|R_var</th>\n",
       "      <th>P(R|L)</th>\n",
       "      <th>P(C|R)</th>\n",
       "      <th>P(L) * P(C|R) * P(R|L)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BXD1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7185</td>\n",
       "      <td>787.00</td>\n",
       "      <td>0.641457</td>\n",
       "      <td>0.346496</td>\n",
       "      <td>585.057</td>\n",
       "      <td>14697.1</td>\n",
       "      <td>0.671956</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>BXD85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2175</td>\n",
       "      <td>605.67</td>\n",
       "      <td>0.641457</td>\n",
       "      <td>0.346496</td>\n",
       "      <td>642.945</td>\n",
       "      <td>14697.1</td>\n",
       "      <td>0.419863</td>\n",
       "      <td>0.003139</td>\n",
       "      <td>0.000659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>BXD8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8990</td>\n",
       "      <td>566.00</td>\n",
       "      <td>0.641457</td>\n",
       "      <td>0.346496</td>\n",
       "      <td>605.996</td>\n",
       "      <td>14697.1</td>\n",
       "      <td>0.615875</td>\n",
       "      <td>0.003116</td>\n",
       "      <td>0.000960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BXD77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>361.23</td>\n",
       "      <td>0.641457</td>\n",
       "      <td>0.346496</td>\n",
       "      <td>573.515</td>\n",
       "      <td>14697.1</td>\n",
       "      <td>0.677243</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>BXD73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2045</td>\n",
       "      <td>572.50</td>\n",
       "      <td>0.641457</td>\n",
       "      <td>0.346496</td>\n",
       "      <td>641.437</td>\n",
       "      <td>14697.1</td>\n",
       "      <td>0.428931</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Individual    L       R       C  R|L_mean   R|L_var C|R_mean  C|R_var  \\\n",
       "0        BXD1  0.0  0.7185  787.00  0.641457  0.346496  585.057  14697.1   \n",
       "36      BXD85  0.0  1.2175  605.67  0.641457  0.346496  642.945  14697.1   \n",
       "35       BXD8  0.0  0.8990  566.00  0.641457  0.346496  605.996  14697.1   \n",
       "34      BXD77  0.0  0.6190  361.23  0.641457  0.346496  573.515  14697.1   \n",
       "33      BXD73  0.0  1.2045  572.50  0.641457  0.346496  641.437  14697.1   \n",
       "\n",
       "      P(R|L)    P(C|R)  P(L) * P(C|R) * P(R|L)  \n",
       "0   0.671956  0.000822                0.000276  \n",
       "36  0.419863  0.003139                0.000659  \n",
       "35  0.615875  0.003116                0.000960  \n",
       "34  0.677243  0.000710                0.000241  \n",
       "33  0.428931  0.002799                0.000600  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_df, m2_df, m3_df = generate_models_df(input_table)\n",
    "m1_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate The Models Likelihood and Likelihood Ratio:\n",
    "\n",
    "Likelihood = L(θ;M) = p(data|θm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Likelihood-Ratio is: 2.53\n"
     ]
    }
   ],
   "source": [
    "LR = get_LR(m1_df, m2_df, m3_df)\n",
    "print(\"The Likelihood-Ratio is: %.2f\" % LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tests = 100\n",
    "LR_dist = []\n",
    "for i in range(0,n_tests):\n",
    "    shuffled_df = get_shuffled_df(input_table.copy())\n",
    "    m1_df, m2_df, m3_df = generate_models_df(shuffled_df)\n",
    "    LR_i = get_LR(m1_df, m2_df, m3_df)\n",
    "    LR_dist.append(LR_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our LR is significant with pval  2.545549829959314e-10\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats \n",
    "import numpy as nupy\n",
    "pval = stats.ttest_1samp(LR_dist, LR)[1]\n",
    "if pval <= 0.05:\n",
    "    print(\"Our LR is significant with pval \", pval)\n",
    "else:\n",
    "    print(\"Our LR is not significant \", pval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
